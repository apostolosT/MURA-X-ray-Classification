{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MURA DenseNet-169 Ensemble",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At-Y9tOJKGb2",
        "colab_type": "text"
      },
      "source": [
        "### Load Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I6I3q3m9p2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "e73f0ccf-125a-4044-8356-af549b2fde14"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWKOjevwhPA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "2f09fa9e-3920-4556-ae66-295d919c4a93"
      },
      "source": [
        "!wget 'https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-05 09:42:53--  https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3380245855 (3.1G) [application/zip]\n",
            "Saving to: ‘MURA-v1.1.zip’\n",
            "\n",
            "MURA-v1.1.zip       100%[===================>]   3.15G  13.5MB/s    in 3m 57s  \n",
            "\n",
            "2020-07-05 09:46:50 (13.6 MB/s) - ‘MURA-v1.1.zip’ saved [3380245855/3380245855]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-99FcpChnAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c4d514a-96a5-4398-b8dc-76537a37cc2c"
      },
      "source": [
        "!unzip MURA-v1.1.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  MURA-v1.1.zip\n",
            "replace MURA-v1.1/train_labeled_studies.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gCzQ0dYg8Ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_path='/content/drive/My Drive/MURA Challenge/data/'\n",
        "path='/content/drive/My Drive/MURA Challenge/data/MURA-v1.1/'\n",
        "colab_path='/content/MURA-v1.1/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpXeoRQpVzex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37c_dWFOWJF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5mbyJIwkBNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs_path=pd.read_csv(colab_path+'train_image_paths.csv',dtype=str,header=None,names=['Img_Path'])\n",
        "train_labels=pd.read_csv(colab_path+'train_labeled_studies.csv',dtype=str,names=['Img_Path','Label'],header=None)\n",
        "test_imgs_path=pd.read_csv(colab_path+'valid_image_paths.csv',dtype=str,header=None,names=['Img_Path'])\n",
        "test_labels=pd.read_csv(colab_path+'valid_labeled_studies.csv',dtype=str,names=['Img_Path','Label'],header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFYeTqguJyC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keep_dir(dir):\n",
        "  x=list(dir.split('/'))\n",
        "  x='/'.join(x[:5])\n",
        "  x=x+'/'\n",
        "  return x\n",
        "def keep_dir2(dir):\n",
        "  x=list(dir.split('/'))\n",
        "  x='/'.join(x[3:5])\n",
        "  x=x+'/'\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1YnMFYUKamx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "18a55caa-9557-4389-d58e-1a087d960773"
      },
      "source": [
        "keep_dir('MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVprIq02-5aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs_path['path_to_merge']=train_imgs_path['Img_Path'].apply(lambda x: keep_dir(x))\n",
        "test_imgs_path['path_to_merge']=test_imgs_path['Img_Path'].apply(lambda x: keep_dir(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnC9bh9AFyS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=train_imgs_path.merge(train_labels,how='inner',left_on='path_to_merge', right_on='Img_Path')\n",
        "test_data=test_imgs_path.merge(test_labels,how='inner',left_on='path_to_merge', right_on='Img_Path')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOYEsugFVYAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['Body_Part']=train_data['Img_Path_x'].apply(lambda x: str(x.split('/')[2]))\n",
        "test_data['Body_Part']=test_data['Img_Path_x'].apply(lambda x: str(x.split('/')[2]))\n",
        "train_data['Patient/Study']=train_data['Img_Path_x'].apply(lambda x: str(x.split('/')[3:5]))\n",
        "test_data['Patient/Study']=test_data['Img_Path_x'].apply(lambda x: str(x.split('/')[3:5]))\n",
        "train_data['Patient/Study']=train_data['Img_Path_x'].apply(lambda x: keep_dir2(x) )\n",
        "test_data['Patient/Study']=test_data['Img_Path_x'].apply(lambda x: keep_dir2(x) )\n",
        "train_data.drop(columns=['path_to_merge','Img_Path_y'],inplace=True)\n",
        "train_data.rename(columns={'Img_Path_x':'Img_Path'},inplace=True)\n",
        "test_data.drop(columns=['path_to_merge','Img_Path_y'],inplace=True)\n",
        "test_data.rename(columns={'Img_Path_x':'Img_Path'},inplace=True)\n",
        "\n",
        "test_labels['Body_Part']=test_labels['Img_Path'].apply(lambda x: str(x.split('/')[2]))\n",
        "test_labels['Patient/Study']=test_labels['Img_Path'].apply(lambda x:  keep_dir2(x))\n",
        "\n",
        "\n",
        "# train_data.Img_Path=train_data.Img_Path.apply(lambda x: drive_path+x)\n",
        "# test_data.Img_Path=test_data.Img_Path.apply(lambda x: drive_path+x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EAJLA8m1J0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b8f0e661-99e6-4671-9933-fee9fdae469c"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Img_Path</th>\n",
              "      <th>Label</th>\n",
              "      <th>Body_Part</th>\n",
              "      <th>Patient/Study</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
              "      <td>1</td>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>patient00001/study1_positive/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
              "      <td>1</td>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>patient00001/study1_positive/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
              "      <td>1</td>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>patient00001/study1_positive/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
              "      <td>1</td>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>patient00002/study1_positive/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
              "      <td>1</td>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>patient00002/study1_positive/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Img_Path  ...                  Patient/Study\n",
              "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study...  ...  patient00001/study1_positive/\n",
              "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study...  ...  patient00001/study1_positive/\n",
              "2  MURA-v1.1/train/XR_SHOULDER/patient00001/study...  ...  patient00001/study1_positive/\n",
              "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study...  ...  patient00002/study1_positive/\n",
              "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study...  ...  patient00002/study1_positive/\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmM7JQnYN8QY",
        "colab_type": "text"
      },
      "source": [
        "### Define Evaluation metrics & Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7YbK6ZsOBOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec3e4cb0-4d90-4a38-bc06-64c343e914c0"
      },
      "source": [
        "import keras.backend as K\n",
        "def recall(y_true, y_pred):\n",
        "    \n",
        "    \"\"\"\n",
        "    Recall metric.\n",
        "    Only computes a batch-wise average of recall.\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \n",
        "    \"\"\"\n",
        "    Precision metric.\n",
        "    Only computes a batch-wise average of precision.\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    Source\n",
        "    ------\n",
        "    https://github.com/fchollet/keras/issues/5400#issuecomment-314747992\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    \n",
        "    \"\"\"Calculate the F1 score.\"\"\"\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * ((p * r) / (p + r))\n",
        "\n",
        "\n",
        "import gc\n",
        "\n",
        "def clean_up(model):\n",
        "    K.clear_session()\n",
        "    del model\n",
        "    gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaPjVXWSer68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for visualizing the training progress of our models\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "def viz_history(hs_dict,metric):\n",
        "  plt.style.use('dark_background')\n",
        "  plt.rcParams['figure.figsize'] = [15, 8]\n",
        "  plt.rcParams['font.size'] = 16\n",
        "  plt.clf()\n",
        "  for model in hs_dict.keys():\n",
        "    plt.plot(hs_dict[model].history[metric],label='{0:s} train {1:s}'.format(model, metric))\n",
        "    plt.plot(hs_dict[model].history['val_{0:s}'.format(metric)],label='{0:s} validation {1:s}'.format(model, metric))\n",
        "    plt.ylabel(metric) \n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFu08tp7GLtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rayGv-uJJ_82",
        "colab_type": "text"
      },
      "source": [
        "### Prep Data For Training\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu8jtNoZ8ksX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array \n",
        "from keras.preprocessing.image import array_to_img\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPoKujeiZpdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffled=train_data.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HJ1s_JzbGFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msk = np.random.rand(len(shuffled)) <0.8\n",
        "\n",
        "train = shuffled[msk]\n",
        "\n",
        "val= shuffled[~msk]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7045qumpG3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications import ResNet101\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.callbacks import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p822p_cb_eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(\n",
        "        optimizer,\n",
        "        body_type='XR_ELBOW',\n",
        "        input_shape=(224,224,3),\n",
        "        output_activation='softmax',\n",
        "        full_network_epochs=10,\n",
        "        callbacks_list=None,\n",
        "        verbose=1,\n",
        "        class_weights=None,\n",
        "        transfer_model=DenseNet169,\n",
        "        pooling='avg'):\n",
        "    \n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=30,\n",
        "      horizontal_flip=True,\n",
        "  )\n",
        "\n",
        "    val_datagen=ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "\n",
        "    train_generator=train_datagen.flow_from_dataframe(\n",
        "        dataframe=train[train.Body_Part==body_type],\n",
        "        directory=None,\n",
        "        x_col=\"Img_Path\",\n",
        "        y_col=\"Label\",\n",
        "        weight_col=None,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        classes=None,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        seed=1,\n",
        "        save_to_dir=None,\n",
        "        save_prefix=\"\",\n",
        "        save_format=\"png\",\n",
        "        interpolation=\"nearest\",\n",
        "        validate_filenames=False,\n",
        "    )\n",
        "\n",
        "    val_generator=val_datagen.flow_from_dataframe(\n",
        "        dataframe=val[val.Body_Part==body_type],\n",
        "        directory=None,\n",
        "        x_col=\"Img_Path\",\n",
        "        y_col=\"Label\",\n",
        "        weight_col=None,\n",
        "        target_size=(224, 224),\n",
        "        color_mode=\"rgb\",\n",
        "        classes=None,\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        seed=1,\n",
        "        save_to_dir=None,\n",
        "        save_prefix=\"\",\n",
        "        save_format=\"png\",\n",
        "        interpolation=\"nearest\",\n",
        "        validate_filenames=False\n",
        "    )\n",
        "\n",
        "    #model parameters for training\n",
        "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "    STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
        "\n",
        "\n",
        "\n",
        "    base_model = transfer_model(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape,\n",
        "        pooling=pooling,\n",
        "    )\n",
        "\n",
        "    x = base_model.output\n",
        "    output = Dense(2, activation='softmax', name='predictions')(x)\n",
        "    model = Model(inputs=base_model.input, output=output)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "    \n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy',f1])\n",
        "    if class_weights:\n",
        "      hs_full_network = model.fit(\n",
        "        train_generator,\n",
        "        epochs=full_network_epochs,\n",
        "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=STEP_SIZE_VALID,\n",
        "        callbacks=callbacks_list,\n",
        "        class_weight=class_weights[body_type],\n",
        "        verbose=1\n",
        "      )\n",
        "    else:\n",
        "      hs_full_network = model.fit(\n",
        "        train_generator,\n",
        "        epochs=full_network_epochs,\n",
        "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=STEP_SIZE_VALID,\n",
        "        callbacks=callbacks_list,\n",
        "        verbose=1\n",
        "      )\n",
        "\n",
        "    print('Finished training full network.')\n",
        "    print('------------------')\n",
        "\n",
        "    return model, hs_full_network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ5KPhPJzgAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import *\n",
        "def evaluate_model(\n",
        "    body_part='XR_ELBOW',\n",
        "    model=None\n",
        "):\n",
        "  test_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=30,\n",
        "      horizontal_flip=True,)\n",
        "  \n",
        "  test_generator=test_datagen.flow_from_dataframe(\n",
        "      dataframe=test_data[test_data.Body_Part==body_part],\n",
        "      directory=None,\n",
        "      x_col=\"Img_Path\",\n",
        "      y_col=\"Label\",\n",
        "      weight_col=None,\n",
        "      target_size=(224, 224),\n",
        "      color_mode=\"rgb\",\n",
        "      classes=None,\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=128,\n",
        "      shuffle=False,\n",
        "      seed=1,\n",
        "      save_to_dir=None,\n",
        "      save_prefix=\"\",\n",
        "      save_format=\"png\",\n",
        "      interpolation=\"nearest\",\n",
        "      validate_filenames=False\n",
        "  )\n",
        "\n",
        "  tta_steps = 10\n",
        "  predictions = []\n",
        "\n",
        "  for i in tqdm(range(tta_steps)):\n",
        "      preds = model.predict(test_generator,verbose=1)\n",
        "      predictions.append(preds)\n",
        "\n",
        "\n",
        "  preds = np.mean(predictions, axis=0)\n",
        "\n",
        "  voting_df=pd.DataFrame(data=np.c_[test_data[test_data.Body_Part==body_part]['Patient/Study'].values,preds],\n",
        "                       columns=['Patient/Study','Class 0 prob','Class 1 prob'])\n",
        "  \n",
        "  voting_df[['Class 0 prob', 'Class 1 prob']] = voting_df[['Class 0 prob', 'Class 1 prob']].apply(pd.to_numeric)   \n",
        "  voting_df=voting_df.groupby('Patient/Study').mean().reset_index()\n",
        "  voting_df['Class_prediction']=np.argmax(voting_df.iloc[:,1:3].values,axis=1)\n",
        "  voting_df=voting_df.merge(test_labels[test_labels.Body_Part==body_part],how='inner',on='Patient/Study')\n",
        "  voting_df=voting_df.drop(columns=['Img_Path'])\n",
        "  voting_df['Label'] = voting_df['Label'].apply(pd.to_numeric) \n",
        "  kappa_score=cohen_kappa_score(voting_df.Class_prediction,voting_df.Label)\n",
        "  f1=f1_score(voting_df.Class_prediction,voting_df.Label)\n",
        "  return [kappa_score,f1,voting_df]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egFC9FQkUqvj",
        "colab_type": "text"
      },
      "source": [
        "### Train for each body part\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB9m8oLE34Si",
        "colab_type": "text"
      },
      "source": [
        "### Train for each body part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBnDfLoVGSRx",
        "colab_type": "text"
      },
      "source": [
        "#### ELBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpGzIZey325U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(1e-4)\n",
        "sncallback_list = [EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,cooldown=2, verbose=1, mode='auto'),\n",
        "            ModelCheckpoint(filepath='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'+'best_model_densenet_XR_ELBOW'+'.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "dense169_model,dense169_hs = train_model(pooling='avg',\n",
        "    body_type='XR_ELBOW',\n",
        "    full_network_epochs=10,\n",
        "    optimizer=optimizer,\n",
        "    output_activation='softmax',\n",
        "    callbacks_list=callback_list ,\n",
        "    verbose=1)\n",
        "\n",
        "clean_up(dense169_model)\n",
        "\n",
        "# res_elbow=evaluate_model(body_part='XR_ELBOW',model=dense169_model)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd0lZTfOGV2I",
        "colab_type": "text"
      },
      "source": [
        "#### FINGER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpS76h6pV4kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "bb685f83-d22c-46a5-be61-6e28fe138b88"
      },
      "source": [
        "optimizer = Adam(1e-4)\n",
        "callback_list = [EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,cooldown=2, verbose=1, mode='auto'),\n",
        "            ModelCheckpoint(filepath='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'+'best_model_densenet_XR_FINGER'+'.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "dense169_model,dense169_hs = train_model(pooling='avg',\n",
        "    body_type='XR_FINGER',\n",
        "    full_network_epochs=10,\n",
        "    optimizer=optimizer,\n",
        "    output_activation='softmax',\n",
        "    callbacks_list=callback_list ,\n",
        "    verbose=1)\n",
        "\n",
        "clean_up(dense169_model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4098 non-validated image filenames belonging to 2 classes.\n",
            "Found 1008 non-validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "128/128 [==============================] - 334s 3s/step - loss: 0.5637 - accuracy: 0.7113 - f1: 0.7134 - val_loss: 0.4345 - val_accuracy: 0.7006 - val_f1: 0.7006\n",
            "Epoch 2/10\n",
            "128/128 [==============================] - 255s 2s/step - loss: 0.4512 - accuracy: 0.7932 - f1: 0.7947 - val_loss: 0.4567 - val_accuracy: 0.7070 - val_f1: 0.7056\n",
            "Epoch 3/10\n",
            "128/128 [==============================] - 254s 2s/step - loss: 0.3861 - accuracy: 0.8306 - f1: 0.8306 - val_loss: 0.3524 - val_accuracy: 0.7777 - val_f1: 0.7792\n",
            "Epoch 4/10\n",
            "128/128 [==============================] - 251s 2s/step - loss: 0.3539 - accuracy: 0.8394 - f1: 0.8345 - val_loss: 0.2280 - val_accuracy: 0.8002 - val_f1: 0.8014\n",
            "Epoch 5/10\n",
            "128/128 [==============================] - 253s 2s/step - loss: 0.3026 - accuracy: 0.8741 - f1: 0.8713 - val_loss: 0.5720 - val_accuracy: 0.7193 - val_f1: 0.7177\n",
            "Epoch 6/10\n",
            "128/128 [==============================] - 253s 2s/step - loss: 0.2871 - accuracy: 0.8812 - f1: 0.8784 - val_loss: 0.5387 - val_accuracy: 0.7992 - val_f1: 0.7994\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/10\n",
            "128/128 [==============================] - 253s 2s/step - loss: 0.1883 - accuracy: 0.9257 - f1: 0.9226 - val_loss: 0.3527 - val_accuracy: 0.8330 - val_f1: 0.8327\n",
            "Epoch 8/10\n",
            "128/128 [==============================] - 253s 2s/step - loss: 0.1599 - accuracy: 0.9439 - f1: 0.9407 - val_loss: 0.4132 - val_accuracy: 0.8453 - val_f1: 0.8448\n",
            "Epoch 9/10\n",
            "128/128 [==============================] - 253s 2s/step - loss: 0.1391 - accuracy: 0.9582 - f1: 0.9548 - val_loss: 0.4484 - val_accuracy: 0.8381 - val_f1: 0.8377\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 00009: early stopping\n",
            "Finished training full network.\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iDxV-6HiqG",
        "colab_type": "text"
      },
      "source": [
        "#### HAND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlAONyM1XteN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "8d398931-0fea-4a3e-9eb7-30b2760a6d20"
      },
      "source": [
        "optimizer = Adam(1e-4)\n",
        "callback_list = [EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,cooldown=2, verbose=1, mode='auto'),\n",
        "            ModelCheckpoint(filepath='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'+'best_model_densenet_XR_HAND'+'.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "dense169_model,dense169_hs = train_model(pooling='avg',\n",
        "    body_type='XR_HAND',\n",
        "    full_network_epochs=10,\n",
        "    optimizer=optimizer,\n",
        "    output_activation='softmax',\n",
        "    callbacks_list=callback_list ,\n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clean_up(dense169_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4425 non-validated image filenames belonging to 2 classes.\n",
            "Found 1118 non-validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "138/138 [==============================] - 359s 3s/step - loss: 0.5493 - accuracy: 0.7530 - f1: 0.7537 - val_loss: 0.5048 - val_accuracy: 0.7454 - val_f1: 0.7454\n",
            "Epoch 2/10\n",
            "138/138 [==============================] - 277s 2s/step - loss: 0.4615 - accuracy: 0.7951 - f1: 0.7962 - val_loss: 0.4514 - val_accuracy: 0.7413 - val_f1: 0.7411\n",
            "Epoch 3/10\n",
            "138/138 [==============================] - 275s 2s/step - loss: 0.4152 - accuracy: 0.8193 - f1: 0.8202 - val_loss: 0.6811 - val_accuracy: 0.7716 - val_f1: 0.7716\n",
            "Epoch 4/10\n",
            "138/138 [==============================] - 275s 2s/step - loss: 0.3786 - accuracy: 0.8372 - f1: 0.8369 - val_loss: 0.6010 - val_accuracy: 0.8149 - val_f1: 0.8149\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/10\n",
            "138/138 [==============================] - 274s 2s/step - loss: 0.2831 - accuracy: 0.8875 - f1: 0.8881 - val_loss: 0.4059 - val_accuracy: 0.8297 - val_f1: 0.8295\n",
            "Epoch 6/10\n",
            "138/138 [==============================] - 275s 2s/step - loss: 0.2618 - accuracy: 0.9008 - f1: 0.9007 - val_loss: 0.4364 - val_accuracy: 0.8232 - val_f1: 0.8231\n",
            "Epoch 7/10\n",
            "138/138 [==============================] - 276s 2s/step - loss: 0.2419 - accuracy: 0.9078 - f1: 0.9078 - val_loss: 0.2303 - val_accuracy: 0.8324 - val_f1: 0.8324\n",
            "Epoch 8/10\n",
            "138/138 [==============================] - 274s 2s/step - loss: 0.2217 - accuracy: 0.9151 - f1: 0.9154 - val_loss: 0.2833 - val_accuracy: 0.8287 - val_f1: 0.8287\n",
            "Epoch 9/10\n",
            "138/138 [==============================] - 275s 2s/step - loss: 0.2115 - accuracy: 0.9251 - f1: 0.9255 - val_loss: 0.4506 - val_accuracy: 0.8287 - val_f1: 0.8287\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 10/10\n",
            "138/138 [==============================] - 275s 2s/step - loss: 0.1945 - accuracy: 0.9292 - f1: 0.9296 - val_loss: 0.5358 - val_accuracy: 0.8287 - val_f1: 0.8287\n",
            "Finished training full network.\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmLfdByXHmal",
        "colab_type": "text"
      },
      "source": [
        "#### HUMEROUS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3djM4KHX2f7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "b55dc202-4f33-4c0c-d412-689a7e46b704"
      },
      "source": [
        "optimizer = Adam(1e-4)\n",
        "callback_list = [EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,cooldown=2, verbose=1, mode='auto'),\n",
        "            ModelCheckpoint(filepath='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'+'best_model_densenet_XR_HUMERUS'+'.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "dense169_model,dense169_hs = train_model(pooling='avg',\n",
        "    body_type='XR_HUMERUS',\n",
        "    full_network_epochs=10,\n",
        "    optimizer=optimizer,\n",
        "    output_activation='softmax',\n",
        "    callbacks_list=callback_list ,\n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clean_up(dense169_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1056 non-validated image filenames belonging to 2 classes.\n",
            "Found 216 non-validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "33/33 [==============================] - 146s 4s/step - loss: 0.5645 - accuracy: 0.7178 - f1: 0.7178 - val_loss: 1.0798 - val_accuracy: 0.5625 - val_f1: 0.5625\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 67s 2s/step - loss: 0.3705 - accuracy: 0.8513 - f1: 0.8513 - val_loss: 0.5240 - val_accuracy: 0.7826 - val_f1: 0.7847\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.3307 - accuracy: 0.8665 - f1: 0.8665 - val_loss: 0.4300 - val_accuracy: 0.7826 - val_f1: 0.7795\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.2332 - accuracy: 0.9167 - f1: 0.9167 - val_loss: 0.4443 - val_accuracy: 0.8370 - val_f1: 0.8351\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.2025 - accuracy: 0.9205 - f1: 0.9205 - val_loss: 0.4988 - val_accuracy: 0.8152 - val_f1: 0.8142\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.1388 - accuracy: 0.9536 - f1: 0.9536 - val_loss: 0.1430 - val_accuracy: 0.8533 - val_f1: 0.8507\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.1179 - accuracy: 0.9631 - f1: 0.9631 - val_loss: 0.4294 - val_accuracy: 0.8424 - val_f1: 0.8420\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.1060 - accuracy: 0.9688 - f1: 0.9688 - val_loss: 0.8144 - val_accuracy: 0.8698 - val_f1: 0.8698\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.0964 - accuracy: 0.9716 - f1: 0.9716 - val_loss: 0.3040 - val_accuracy: 0.8696 - val_f1: 0.8681\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 65s 2s/step - loss: 0.0948 - accuracy: 0.9716 - f1: 0.9716 - val_loss: 0.3984 - val_accuracy: 0.8587 - val_f1: 0.8611\n",
            "Finished training full network.\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_tOO9-4HpOJ",
        "colab_type": "text"
      },
      "source": [
        "#### FOREARM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvBIiseZPs73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "b27404ee-5cbb-45f5-cc60-044044897ee2"
      },
      "source": [
        "optimizer = Adam(1e-4)\n",
        "callback_list = [EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,cooldown=2, verbose=1, mode='auto'),\n",
        "            ModelCheckpoint(filepath='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'+'best_model_densenet_XR_FOREARM'+'.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "dense169_model,dense169_hs = train_model(pooling='avg',\n",
        "    body_type='XR_FOREARM',\n",
        "    full_network_epochs=10,\n",
        "    optimizer=optimizer,\n",
        "    output_activation='softmax',\n",
        "    callbacks_list=callback_list ,\n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clean_up(dense169_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1457 non-validated image filenames belonging to 2 classes.\n",
            "Found 368 non-validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 175s 4s/step - loss: 0.5123 - accuracy: 0.7705 - f1: 0.7699 - val_loss: 0.7349 - val_accuracy: 0.7415 - val_f1: 0.7415\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.3598 - accuracy: 0.8618 - f1: 0.8620 - val_loss: 0.5425 - val_accuracy: 0.7202 - val_f1: 0.7131\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.2813 - accuracy: 0.8954 - f1: 0.8965 - val_loss: 0.7186 - val_accuracy: 0.7738 - val_f1: 0.7699\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.2430 - accuracy: 0.9074 - f1: 0.9083 - val_loss: 0.4719 - val_accuracy: 0.8244 - val_f1: 0.8153\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.1878 - accuracy: 0.9242 - f1: 0.9250 - val_loss: 1.1291 - val_accuracy: 0.8095 - val_f1: 0.7983\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.1532 - accuracy: 0.9396 - f1: 0.9397 - val_loss: 0.5187 - val_accuracy: 0.8214 - val_f1: 0.8182\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 89s 2s/step - loss: 0.0973 - accuracy: 0.9719 - f1: 0.9722 - val_loss: 0.3445 - val_accuracy: 0.8304 - val_f1: 0.8239\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 90s 2s/step - loss: 0.0817 - accuracy: 0.9785 - f1: 0.9785 - val_loss: 0.3949 - val_accuracy: 0.8214 - val_f1: 0.8153\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 88s 2s/step - loss: 0.0737 - accuracy: 0.9794 - f1: 0.9799 - val_loss: 0.1868 - val_accuracy: 0.8214 - val_f1: 0.8153\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 90s 2s/step - loss: 0.0612 - accuracy: 0.9854 - f1: 0.9854 - val_loss: 0.3988 - val_accuracy: 0.8333 - val_f1: 0.8295\n",
            "Finished training full network.\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFRcVdvBHspf",
        "colab_type": "text"
      },
      "source": [
        "#### SHOULDER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWEC1G4VDaaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "225a234e-2ff7-4735-f46c-123b21f4076e"
      },
      "source": [
        "optimizer = Adam(1e-4)\n",
        "callback_list = [EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,cooldown=2, verbose=1, mode='auto'),\n",
        "            ModelCheckpoint(filepath='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'+'best_model_densenet_XR_SHOULDER'+'.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "dense169_model,dense169_hs = train_model(pooling='avg',\n",
        "    body_type='XR_SHOULDER',\n",
        "    full_network_epochs=10,\n",
        "    optimizer=optimizer,\n",
        "    output_activation='softmax',\n",
        "    callbacks_list=callback_list ,\n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clean_up(dense169_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6716 non-validated image filenames belonging to 2 classes.\n",
            "Found 1663 non-validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "209/209 [==============================] - 513s 2s/step - loss: 0.5875 - accuracy: 0.7081 - f1: 0.7082 - val_loss: 0.6792 - val_accuracy: 0.6213 - val_f1: 0.6213\n",
            "Epoch 2/10\n",
            "209/209 [==============================] - 420s 2s/step - loss: 0.4992 - accuracy: 0.7721 - f1: 0.7722 - val_loss: 0.6438 - val_accuracy: 0.7069 - val_f1: 0.7069\n",
            "Epoch 3/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.4539 - accuracy: 0.7958 - f1: 0.7958 - val_loss: 0.4419 - val_accuracy: 0.7529 - val_f1: 0.7528\n",
            "Epoch 4/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.4116 - accuracy: 0.8167 - f1: 0.8168 - val_loss: 0.8639 - val_accuracy: 0.7039 - val_f1: 0.7039\n",
            "Epoch 5/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.3746 - accuracy: 0.8374 - f1: 0.8375 - val_loss: 0.5309 - val_accuracy: 0.7615 - val_f1: 0.7614\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 6/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.2842 - accuracy: 0.8848 - f1: 0.8848 - val_loss: 0.5816 - val_accuracy: 0.7805 - val_f1: 0.7804\n",
            "Epoch 7/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.2602 - accuracy: 0.8959 - f1: 0.8959 - val_loss: 0.5919 - val_accuracy: 0.7934 - val_f1: 0.7933\n",
            "Epoch 8/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.2334 - accuracy: 0.9083 - f1: 0.9083 - val_loss: 0.4054 - val_accuracy: 0.7811 - val_f1: 0.7811\n",
            "Epoch 9/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.2181 - accuracy: 0.9161 - f1: 0.9161 - val_loss: 0.5375 - val_accuracy: 0.7860 - val_f1: 0.7860\n",
            "Epoch 10/10\n",
            "209/209 [==============================] - 418s 2s/step - loss: 0.1936 - accuracy: 0.9280 - f1: 0.9281 - val_loss: 0.2975 - val_accuracy: 0.7793 - val_f1: 0.7792\n",
            "Finished training full network.\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14szgGgFHwKa",
        "colab_type": "text"
      },
      "source": [
        "#### WRIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP2QMq_YDqLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "234bf783-bc20-4e31-a262-f773fa5bad58"
      },
      "source": [
        "optimizer = Adam(1e-4)\n",
        "callback_list = [EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,cooldown=2, verbose=1, mode='auto'),\n",
        "            ModelCheckpoint(filepath='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'+'best_model_densenet_XR_WRIST'+'.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "dense169_model,dense169_hs = train_model(pooling='avg',\n",
        "    body_type='XR_WRIST',\n",
        "    full_network_epochs=10,\n",
        "    optimizer=optimizer,\n",
        "    output_activation='softmax',\n",
        "    callbacks_list=callback_list ,\n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clean_up(dense169_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7721 non-validated image filenames belonging to 2 classes.\n",
            "Found 2031 non-validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "241/241 [==============================] - 564s 2s/step - loss: 0.4858 - accuracy: 0.7757 - f1: 0.7760 - val_loss: 0.5279 - val_accuracy: 0.7634 - val_f1: 0.7634\n",
            "Epoch 2/10\n",
            "241/241 [==============================] - 484s 2s/step - loss: 0.3946 - accuracy: 0.8344 - f1: 0.8343 - val_loss: 0.3294 - val_accuracy: 0.8099 - val_f1: 0.8104\n",
            "Epoch 3/10\n",
            "241/241 [==============================] - 483s 2s/step - loss: 0.3500 - accuracy: 0.8547 - f1: 0.8545 - val_loss: 0.7731 - val_accuracy: 0.8249 - val_f1: 0.8253\n",
            "Epoch 4/10\n",
            "241/241 [==============================] - 483s 2s/step - loss: 0.3223 - accuracy: 0.8591 - f1: 0.8592 - val_loss: 0.5847 - val_accuracy: 0.8264 - val_f1: 0.8268\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/10\n",
            "241/241 [==============================] - 483s 2s/step - loss: 0.2558 - accuracy: 0.8963 - f1: 0.8967 - val_loss: 0.3593 - val_accuracy: 0.8529 - val_f1: 0.8536\n",
            "Epoch 6/10\n",
            "241/241 [==============================] - 482s 2s/step - loss: 0.2280 - accuracy: 0.9104 - f1: 0.9107 - val_loss: 0.3387 - val_accuracy: 0.8529 - val_f1: 0.8536\n",
            "Epoch 7/10\n",
            "241/241 [==============================] - 483s 2s/step - loss: 0.2129 - accuracy: 0.9139 - f1: 0.9142 - val_loss: 0.4040 - val_accuracy: 0.8559 - val_f1: 0.8566\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 00007: early stopping\n",
            "Finished training full network.\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH4mVPOTgMXb",
        "colab_type": "text"
      },
      "source": [
        "### Load Model From Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4TrfuXygQu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_saved_models='/content/drive/My Drive/Deep Learning/Saved Models Project 2/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFJEVy5GdNiJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "b339bde5-60d1-4330-d995-431fdebfdb61"
      },
      "source": [
        "os.listdir(path_to_saved_models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_model_freezed.h5',\n",
              " 'best_model_densenet.h5',\n",
              " 'XR_FOREARM_best_model_densenet.h5',\n",
              " 'XR_HUMERUS_best_model_densenet.h5',\n",
              " 'XR_FINGER_best_model_densenet.h5',\n",
              " 'XR_ELBOW_best_model_densenet.h5',\n",
              " 'XR_HAND_best_model_densenet.h5',\n",
              " 'XR_SHOULDER_best_model_densenet.h5',\n",
              " 'XR_WRIST_best_model_densenet.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL-WXFy66fMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_model_list=os.listdir(path_to_saved_models)[2:]\n",
        "bone_category=[]\n",
        "for i in load_model_list:\n",
        "  bone_category.append('_'.join(i.split('_')[0:2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZBgnDhU7wi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "e5fee32b-f9d1-4a0b-d4e6-6139c7f17916"
      },
      "source": [
        "bone_category"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['XR_FOREARM',\n",
              " 'XR_HUMERUS',\n",
              " 'XR_FINGER',\n",
              " 'XR_ELBOW',\n",
              " 'XR_HAND',\n",
              " 'XR_SHOULDER',\n",
              " 'XR_WRIST']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UToAYYaThoNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "2c70b213-97e2-4809-c00a-f3144023373a"
      },
      "source": [
        "loaded_models={}\n",
        "for idx,model in zip(bone_category,load_model_list):\n",
        "  print('Loading model {} ...'.format(idx))\n",
        "  loaded_models[idx]=keras.models.load_model(path_to_saved_models+model,custom_objects={\n",
        "        \"f1\":f1,\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model XR_FOREARM ...\n",
            "Loading model XR_HUMERUS ...\n",
            "Loading model XR_FINGER ...\n",
            "Loading model XR_ELBOW ...\n",
            "Loading model XR_HAND ...\n",
            "Loading model XR_SHOULDER ...\n",
            "Loading model XR_WRIST ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBi93gC2l6HM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e30898ed-7df1-45a3-811c-4bedc4da05e6"
      },
      "source": [
        "eval_results={}\n",
        "for k,v in loaded_models.items():\n",
        "  eval_results[k]=evaluate_model(k,v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 301 non-validated image filenames belonging to 2 classes.\n",
            "3/3 [==============================] - 3s 877ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:10<01:37, 10.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 877ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:17<01:17,  9.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 881ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:25<01:02,  8.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 913ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:32<00:50,  8.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 896ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:39<00:40,  8.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 905ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:46<00:31,  7.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 874ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:53<00:22,  7.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 865ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:00<00:14,  7.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 872ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:08<00:07,  7.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 876ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:15<00:00,  7.51s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 288 non-validated image filenames belonging to 2 classes.\n",
            "3/3 [==============================] - 3s 853ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:09<01:28,  9.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 796ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:16<01:11,  8.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 795ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:23<00:58,  8.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 789ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:30<00:46,  7.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 793ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:36<00:37,  7.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 783ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:43<00:29,  7.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 814ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:50<00:21,  7.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 822ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [00:57<00:14,  7.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 818ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:04<00:07,  7.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 815ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:11<00:00,  7.12s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 461 non-validated image filenames belonging to 2 classes.\n",
            "4/4 [==============================] - 10s 2s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:17<02:33, 17.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:26<01:58, 14.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:36<01:33, 13.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:46<01:13, 12.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:55<00:57, 11.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:05<00:43, 10.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [01:15<00:31, 10.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:24<00:20, 10.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:34<00:10, 10.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:44<00:00, 10.42s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 465 non-validated image filenames belonging to 2 classes.\n",
            "4/4 [==============================] - 10s 2s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:17<02:38, 17.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:27<02:02, 15.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:37<01:36, 13.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:47<01:15, 12.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:58<00:59, 11.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:08<00:45, 11.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [01:18<00:33, 11.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:28<00:21, 10.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:38<00:10, 10.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:48<00:00, 10.87s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 460 non-validated image filenames belonging to 2 classes.\n",
            "4/4 [==============================] - 10s 2s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:17<02:35, 17.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:27<02:00, 15.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:37<01:34, 13.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:47<01:14, 12.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:56<00:58, 11.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:06<00:44, 11.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [01:16<00:32, 10.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:26<00:21, 10.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:36<00:10, 10.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:46<00:00, 10.68s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 563 non-validated image filenames belonging to 2 classes.\n",
            "5/5 [==============================] - 10s 2s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:18<02:43, 18.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:29<02:09, 16.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:41<01:43, 14.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:53<01:23, 13.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:04<01:06, 13.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:16<00:50, 12.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [01:27<00:37, 12.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:39<00:24, 12.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [01:51<00:12, 12.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:02<00:00, 12.29s/it]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 659 non-validated image filenames belonging to 2 classes.\n",
            "6/6 [==============================] - 11s 2s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:18<02:48, 18.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:32<02:17, 17.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:45<01:51, 15.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:58<01:31, 15.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [01:11<01:13, 14.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [01:25<00:56, 14.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [01:38<00:41, 13.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [01:51<00:27, 13.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [02:05<00:13, 13.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 9s 1s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:18<00:00, 13.85s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aY0yNM7nN1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "1f37e4b8-d4f5-4304-854f-356315210465"
      },
      "source": [
        "for k,v in eval_results.items():\n",
        "  print('{}: Kappa Score {:.3f} f1 {:.3f}'.format(k,v[0],v[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XR_FOREARM: Kappa Score 0.665 f1 0.796\n",
            "XR_HUMERUS: Kappa Score 0.733 f1 0.859\n",
            "XR_FINGER: Kappa Score 0.533 f1 0.706\n",
            "XR_ELBOW: Kappa Score 0.682 f1 0.806\n",
            "XR_HAND: Kappa Score 0.501 f1 0.648\n",
            "XR_SHOULDER: Kappa Score 0.628 f1 0.806\n",
            "XR_WRIST: Kappa Score 0.709 f1 0.810\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}